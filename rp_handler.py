import io
import os
import base64
import torch
from PIL import Image
from diffusers import DiffusionPipeline, FlowMatchEulerDiscreteScheduler
import runpod
import requests

# è¯»å–æ¨¡å‹è·¯å¾„ï¼ˆRunPod ç¼“å­˜ï¼‰
MODEL_PATH = os.getenv("MODEL_PATH", "Qwen/Qwen-Image")
LORA_PATH = os.getenv("LORA_PATH", "lightx2v/Qwen-Image-Lightning")
LORA_WEIGHT = os.getenv("LORA_WEIGHT", "Qwen-Image-Lightning-8steps-V1.0.safetensors")

# åˆå§‹åŒ–æ¨¡å‹ï¼ŒåªåŠ è½½ä¸€æ¬¡ï¼ˆåœ¨å®¹å™¨å¯åŠ¨æ—¶ï¼‰
print(f"ğŸ”¹ Loading model from: {MODEL_PATH}")
scheduler = FlowMatchEulerDiscreteScheduler.from_config(MODEL_PATH)
pipe = DiffusionPipeline.from_pretrained(
    MODEL_PATH,
    scheduler=scheduler,
    torch_dtype=torch.bfloat16
)
print(f"ğŸ”¹ Loading LoRA: {LORA_PATH}")
pipe.load_lora_weights(LORA_PATH, weight_name=LORA_WEIGHT)
pipe.to("cuda")
pipe.enable_xformers_memory_efficient_attention()

# ä¸»å¤„ç†å‡½æ•°
def handler(event):
    input_data = event.get("input", {})
    image_url = input_data.get("image_url")

    if not image_url:
        return {"error": "Missing image_url in input"}

    # ä¸‹è½½è¾“å…¥å›¾åƒ
    resp = requests.get(image_url)
    image = Image.open(io.BytesIO(resp.content)).convert("RGB")

    # ç”Ÿæˆæ¸…ç†åçš„å›¾åƒ
    with torch.autocast("cuda"):
        result = pipe(
            prompt="product photo with clean isolated subject, no background",
            negative_prompt="background, clutter, shadows, multiple objects",
            image=image,
            num_inference_steps=8,
            width=1024,
            height=1024,
        ).images[0]

    # è½¬ base64
    buf = io.BytesIO()
    result.save(buf, format="PNG")
    encoded = base64.b64encode(buf.getvalue()).decode("utf-8")

    return {"status": "success", "image_base64": encoded}

# RunPod Serverless å¯åŠ¨
runpod.serverless.start({"handler": handler})
